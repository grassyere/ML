# -*- coding: utf-8 -*-
"""CourseWork.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cgsHU1_4NksJkKwuvRdy4vaiFDThzwR1
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import SGDClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score, recall_score
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, median_absolute_error, r2_score 
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import KFold, RepeatedKFold, ShuffleSplit, StratifiedKFold
from sklearn.model_selection import learning_curve, validation_curve

import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

#Загружаем данные и выводим первые 5 строк
data=pd.read_csv("/content/pulsar_stars.csv")
data.head()

# Размер  датасета
data.shape

# Список колонок
data.columns

# Список колонок с типами данных 
data.dtypes

data.info()

data.isnull().sum()

# Основные статистические характеристки набора данных
data.describe()

# Парные диаграммы
sns.pairplot(data)

#Комбинация гистограмм и диаграмм рассеивания для всего набора данных.
sns.pairplot(data, hue="target_class")

# Убедимся, что целевой признак
# для задачи бинарной классификации содержит только 0 и 1
data['target_class'].unique()

# Оценим дисбаланс классов для целевого признака
fig, ax = plt.subplots(figsize=(2,2)) 
plt.hist(data['target_class'])
plt.show()

data['target_class'].value_counts()

# посчитаем дисбаланс классов
total = data.shape[0]
class_0, class_1 = data['target_class'].value_counts()
print('Класс 0 составляет {}%, а класс 1 составляет {}%.'
      .format(round(class_0 / total, 4)*100, round(class_1 / total, 4)*100))

data.columns

# Скрипичные диаграммы для числовых колонок
for col in [' Mean of the integrated profile',
       ' Standard deviation of the integrated profile',
       ' Excess kurtosis of the integrated profile',
       ' Skewness of the integrated profile', ' Mean of the DM-SNR curve',
       ' Standard deviation of the DM-SNR curve',
       ' Excess kurtosis of the DM-SNR curve', ' Skewness of the DM-SNR curve']:
    sns.violinplot(x=data[col])
    plt.show()

# Выбор признаков, подходящих для построения моделей.
# Кодирование категориальных признаков. Масштабирование данных. 
# Формирование вспомогательных признаков, улучшающих качество моделей.

data.dtypes

data.head()

# Числовые колонки для масштабирования
scale_cols = [' Mean of the integrated profile',
       ' Standard deviation of the integrated profile',
       ' Excess kurtosis of the integrated profile',
       ' Skewness of the integrated profile', ' Mean of the DM-SNR curve',
       ' Standard deviation of the DM-SNR curve',
       ' Excess kurtosis of the DM-SNR curve', ' Skewness of the DM-SNR curve']

from sklearn.preprocessing import MinMaxScaler
sc1 = MinMaxScaler()
sc1_data = sc1.fit_transform(data[scale_cols])

# Добавим масштабированные данные в набор данных
for i in range(len(scale_cols)):
    col = scale_cols[i]
    new_col_name = col + '_scaled'
    data[new_col_name] = sc1_data[:,i]

data.head()

# Проверим, что масштабирование не повлияло на распределение данных
for col in scale_cols:
    col_scaled = col + '_scaled'

    fig, ax = plt.subplots(1, 2, figsize=(8,3))
    ax[0].hist(data[col], 50)
    ax[1].hist(data[col_scaled], 50)
    ax[0].title.set_text(col)
    ax[1].title.set_text(col_scaled)
    plt.show()

#Проведение корреляционного анализа данных. 
#Формирование промежуточных выводов о возможности построения моделей машинного обучения.

corr_cols_1 = scale_cols + ['target_class']
corr_cols_1

scale_cols_postfix = [x+'_scaled' for x in scale_cols]
corr_cols_2 = scale_cols_postfix + ['target_class']
corr_cols_2

fig, ax = plt.subplots(figsize=(10,5))
sns.heatmap(data[corr_cols_1].corr(), annot=True, fmt='.2f')

fig, ax = plt.subplots(figsize=(10,5))
sns.heatmap(data[corr_cols_2].corr(), annot=True, fmt='.2f')

#Сохранение и визуализация метрик

class MetricLogger:
    
    def __init__(self):
        self.df = pd.DataFrame(
            {'metric': pd.Series([], dtype='str'),
            'alg': pd.Series([], dtype='str'),
            'value': pd.Series([], dtype='float')})

    def add(self, metric, alg, value):
        """
        Добавление значения
        """
        # Удаление значения если оно уже было ранее добавлено
        self.df.drop(self.df[(self.df['metric']==metric)&(self.df['alg']==alg)].index, inplace = True)
        # Добавление нового значения
        temp = [{'metric':metric, 'alg':alg, 'value':value}]
        self.df = self.df.append(temp, ignore_index=True)

    def get_data_for_metric(self, metric, ascending=True):
        """
        Формирование данных с фильтром по метрике
        """
        temp_data = self.df[self.df['metric']==metric]
        temp_data_2 = temp_data.sort_values(by='value', ascending=ascending)
        return temp_data_2['alg'].values, temp_data_2['value'].values
    
    def plot(self, str_header, metric, ascending=True, figsize=(5, 5)):
        """
        Вывод графика
        """
        array_labels, array_metric = self.get_data_for_metric(metric, ascending)
        fig, ax1 = plt.subplots(figsize=figsize)
        pos = np.arange(len(array_metric))
        rects = ax1.barh(pos, array_metric,
                         align='center',
                         height=0.5, 
                         tick_label=array_labels)
        ax1.set_title(str_header)
        for a,b in zip(pos, array_metric):
            plt.text(0.5, a-0.05, str(round(b,3)), color='white')
        plt.show()

#Формирование обучающей и тестовой выборок на основе исходного набора данных.

target = data['target_class']
data = data.drop('target_class', axis = 1)

data.columns

data.head()

# Признаки для задачи классификации
task_clas_cols = [' Excess kurtosis of the integrated profile_scaled',
       ' Skewness of the integrated profile_scaled',
       ' Mean of the DM-SNR curve_scaled',
       ' Standard deviation of the DM-SNR curve_scaled',]

# Выборки для задачи классификации
clas_data = data[task_clas_cols]

clas_data.head()

#деление на тестовую и обучающую выборку
clas_X_train, clas_X_test, clas_Y_train, clas_Y_test = train_test_split(
    clas_data, target, test_size=0.2, random_state=1)
clas_X_train.shape, clas_X_test.shape, clas_Y_train.shape, clas_Y_test.shape

#Построение базового решения (baseline) для выбранных моделей без подбора гиперпараметров. 
#Производится обучение моделей на основе обучающей выборки и оценка качества моделей на основе тестовой выборки.

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier
from sklearn.metrics import accuracy_score, balanced_accuracy_score
from sklearn.metrics import precision_score, recall_score, f1_score, classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import plot_confusion_matrix
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, median_absolute_error, r2_score 
from sklearn.metrics import roc_curve, roc_auc_score
from sklearn.svm import SVC, NuSVC, LinearSVC, OneClassSVM, SVR, NuSVR, LinearSVR
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, export_graphviz
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor
from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor
# %matplotlib inline 
sns.set(style="ticks")

from sklearn.linear_model import LogisticRegression
# Модели
clas_models = {'LogR': LogisticRegression(), 
               'SVC':SVC(),
               'Tree':DecisionTreeClassifier(),
               'RF':RandomForestClassifier(),
               'GB':GradientBoostingClassifier()}

# Сохранение метрик
clasMetricLogger = MetricLogger()

def clas_train_model(model_name, model, clasMetricLogger):
    model.fit(clas_X_train, clas_Y_train)
    Y_pred = model.predict(clas_X_test)
    precision = precision_score(clas_Y_test.values, Y_pred)
    recall = recall_score(clas_Y_test.values, Y_pred)
    f1 = f1_score(clas_Y_test.values, Y_pred)
    roc_auc = roc_auc_score(clas_Y_test.values, Y_pred)
    
    clasMetricLogger.add('precision', model_name, precision)
    clasMetricLogger.add('recall', model_name, recall)
    clasMetricLogger.add('f1', model_name, f1)
    clasMetricLogger.add('roc_auc', model_name, roc_auc)

    print('*****************************************************')
    print(model)
    print('*****************************************************')
    draw_roc_curve(clas_Y_test.values, Y_pred)
    
    plot_confusion_matrix(model, clas_X_test, clas_Y_test.values, 
                      display_labels=['0','1'], 
                      cmap=plt.cm.Blues, normalize='true')
    plt.show()

# Отрисовка ROC-кривой
def draw_roc_curve(y_true, y_score, pos_label=1, average='micro'):
    fpr, tpr, thresholds = roc_curve(y_true, y_score, 
                                     pos_label=pos_label)
    roc_auc_value = roc_auc_score(y_true, y_score, average=average)
    plt.figure()
    lw = 2
    plt.plot(fpr, tpr, color='darkorange',
             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc_value)
    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver operating characteristic')
    plt.legend(loc="lower right")
    plt.show()

for model_name, model in clas_models.items():
    clas_train_model(model_name, model, clasMetricLogger)

#Подбор гиперпараметров для выбранных моделей. Рекомендуется использовать методы кросс-валидации. 
#В зависимости от используемой библиотеки можно применять функцию GridSearchCV, 
#использовать перебор параметров в цикле, или использовать другие методы.¶

clas_X_train.shape

#Кроссвалидация
scores_log = cross_val_score(LogisticRegression(), 
                         clas_X_train, clas_Y_train, cv=2)
# Значение метрики accuracy для 2 фолдов
scores_log, np.mean(scores_log)

scores_svc = cross_val_score(SVC(gamma='auto'), 
                         clas_X_train, clas_Y_train, cv=2)
# Значение метрики accuracy для 2 фолдов
scores_svc, np.mean(scores_svc)

scores_tree = cross_val_score(DecisionTreeClassifier(), 
                         clas_X_train, clas_Y_train, cv=2)
# Значение метрики accuracy для 2 фолдов
scores_tree, np.mean(scores_tree)

scores_rand_tree = cross_val_score(RandomForestClassifier(), 
                         clas_X_train, clas_Y_train, cv=2)
# Значение метрики accuracy для 2 фолдов
scores_rand_tree, np.mean(scores_rand_tree)

scores_boost = cross_val_score(GradientBoostingClassifier(), 
                         clas_X_train, clas_Y_train, cv=2)
# Значение метрики accuracy для 2 фолдов
scores_boost, np.mean(scores_boost)

parameters = {'penalty':['l1', 'l2', 'elasticnet']}
clf_gs_log = GridSearchCV(LogisticRegression(), parameters, cv=5, scoring='accuracy')
clf_gs_log.fit(clas_X_train, clas_Y_train)

# Лучшая модель
clf_gs_log.best_estimator_

# Лучшее значение параметров
clf_gs_log.best_params_

parameters = {'gamma':[160,150,130,120,110,100,50]}
clf_gs_svm_svc = GridSearchCV(SVC(), parameters, cv=5, scoring='accuracy')
clf_gs_svm_svc.fit(clas_X_train, clas_Y_train)

# Лучшая модель
clf_gs_svm_svc.best_estimator_

# Лучшее значение параметров
clf_gs_svm_svc.best_params_

# Изменение качества на тестовой выборке в зависимости от параметра
n_range = np.array([160,150,130,120,110,100,50])
plt.plot(n_range, clf_gs_svm_svc.cv_results_['mean_test_score'])

parameters = {'max_depth':[20,15,10,6,5,4,3], 'min_samples_split':[10,8,6,5,4,3,2]}
clf_gs_decision_tree = GridSearchCV(DecisionTreeClassifier(), parameters, cv=5, scoring='accuracy')
clf_gs_decision_tree.fit(clas_X_train, clas_Y_train)

# Лучшая модель
clf_gs_decision_tree.best_estimator_

# Лучшее значение параметров
clf_gs_decision_tree.best_params_

parameters_random_forest = {'n_estimators':[1, 3, 5, 6, 7, 8, 10], 
                            'max_depth':[1, 3, 5, 6, 7, 8, 10],
                            'random_state':[0, 2, 4, 6, 8, 10, 15]}
best_random_forest = GridSearchCV(RandomForestClassifier(), parameters_random_forest, cv=5, scoring='accuracy')
best_random_forest.fit(clas_X_train, clas_Y_train)

# Лучшая модель
best_random_forest.best_estimator_

best_random_forest.best_params_

parameters_gradient_boosting = {'n_estimators':[3, 5, 7, 10, 15, 20], 
                            'max_depth':[3, 5, 7, 9, 10, 15]}
best_gradient_boosting = GridSearchCV(GradientBoostingClassifier(), parameters_gradient_boosting, cv=5, scoring='accuracy')
best_gradient_boosting.fit(clas_X_train, clas_Y_train)

# Лучшая модель
best_gradient_boosting.best_estimator_

best_gradient_boosting.best_params_

#Повторение пункта 8 для найденных оптимальных значений гиперпараметров. 
#Сравнение качества полученных моделей с качеством baseline-моделей.

# Новые модели с подобранными гиперпараматерами
clas_models_grid = {'LogR':clf_gs_log.best_estimator_, 
               'SVC':clf_gs_svm_svc.best_estimator_,
               'Tree':clf_gs_decision_tree.best_estimator_,
               'RF':best_random_forest.best_estimator_,
               'GB':best_gradient_boosting.best_estimator_}

for model_name, model in clas_models_grid.items():
    clas_train_model(model_name, model, clasMetricLogger)

#Формирование выводов о качестве построенных моделей на основе выбранных метрик.

# Метрики качества модели
clas_metrics = clasMetricLogger.df['metric'].unique()
clas_metrics

# Построим графики метрик качества модели
for metric in clas_metrics:
    clasMetricLogger.plot('Метрика: ' + metric, metric, figsize=(7, 6))